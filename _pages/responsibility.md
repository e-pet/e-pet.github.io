---
title: "Social responsibility"
permalink: /responsibility/
author_profile: true
redirect_from:
---

{% include base_path %}

There are many ways to act responsibly as a researcher, and I personally try to follow at least a few of them.
I think this is one of the many places where the 'boy scout rule' is applicable:
> Leave every place better than you found it.

In other words, when feeling overwhelmed by the challenge of doing *everything* right, I just try to start with *something* and make it a little bit better.

Some things us **machine learning researchers** can do:
- _evaluate_ our models thoroughly to prevent hugely exaggerated performance claims [[1]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7222643/), [[2]](https://www.jclinepi.com/article/S0895-4356(18)31081-3/fulltext), [[3]](https://arxiv.org/abs/2011.03395)
- follow the [TRIPOD guidelines](https://www.tripod-statement.org/resources/) when repording clinical risk prediction models
- perform an _algorithmic impact assessment_ [[1]](https://www.adalovelaceinstitute.org/wp-content/uploads/2020/04/Ada-Lovelace-Institute-DataKind-UK-Examining-the-Black-Box-Report-2020.pdf), [[2]](https://dl.acm.org/doi/pdf/10.1145/3442188.3445935)
- assess the [climate impact of our ML projects](https://www.nature.com/articles/s42256-020-0219-9), and support the [Climate Change AI Initiative](https://www.climatechange.ai/)
- support a ban on lethal autonomous weapons (see [[1]](https://futureoflife.org/lethal-autonomous-weapons-pledge), [[2]](https://www.stopkillerrobots.org/), [[3]](https://autonomousweapons.org/)), and the various recent initiatives on ethical AI (see, e.g., [CHAI](https://humancompatible.ai/), [FLI](https://futureoflife.org/background/benefits-risks-of-artificial-intelligence/), [80000 hours](https://80000hours.org/problem-profiles/positively-shaping-artificial-intelligence/), [EML](https://ethical.institute/index.html), [EU initiatives](https://futureoflife.org/ai-policy-european-union/))


Some things **all researchers** can do:
- make research _openly accessible_ (paper, code), _correct_, and _reproducible_ (if interested, see some very basic [best practices for scientific software development](https://github.com/e-pet/best-practices-scientific-software-dev/blob/master/best_practices_scientific_software_dev.md) that I wrote quite a while ago)
- aim for [design justice](https://designjustice.org/read-the-principles) by giving those who will be affected by our research a voice in it
- support the [Scientists for future](https://scientists4future.org/) and, in particular, their [I won't do it under 1000km](https://unter1000.scientists4future.org/) initiative
- if currently thinking about the next educational or career move or a research project, head over to [80000 Hours](https://80000hours.org) and check out their well-researched advice


Let me know if you think something crucial is missing that I should add!
